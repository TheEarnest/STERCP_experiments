#!/bin/ksh
#SBATCH --account=nn9385k
#SBATCH --job-name=ECHAM6_t1SP_a9
#SBATCH --output=r_ECHAM6_t1SP_a9_out_%j
#SBATCH --time=0-0:50:0
#SBATCH --nodes=8 --ntasks-per-node=32
#SBATCH --mail-type=ALL
#SBATCH --mail-user=earnestshen@gmail.com

###############################################################################
#                              ECHAM6_t1SP_a9.run
#   Automatically generated by Create_TASKS.frm using the m4 macro processor.
###############################################################################
#
#   R U N - Script for the model configuration mpiesm-as
#
#      ECHAM - global atmosphere GCM (MPI-Met)
#
###############################################################################

###############################################################################

set -e
export task=RUN     # The task: RUN, ARCH, POST, MON, REM
print "\n Start of script at\t$(date)\n - on host or node\t$(hostname)"


#------------------------------------------------------------------------------
#        SETUP OF EXPERIMENT ECHAM6_t1SP_a9
#------------------------------------------------------------------------------

#
#-- Project ID
#

export proid=c5_
export groupwrite=no

#
#-- Experiment ID
#

export expid=ECHAM6_t1SP_a9
export parent_experiment="N/A"                                         # CMOR CV
export parent_member="N/A"                                             # CMOR CV
export parent_branch_time=00000000,00000000
export forcing_text="GHG Oz SD Sl Vl LU"                               # CMOR CV

#
#-- Coupled model name
#

export cplmod=mpiesm-as

#
#-- Node name / OS of the computing host
#

export node=hexagon

#
#-- components
#

atmmod=echam6
srfmod=jsbach

###############################################################################
#
#     USER INTERFACE
#
###############################################################################

export verbose=yes                # yes/no 

#------------------------------------------------------------------------------
#   Configuration of component(s)
#------------------------------------------------------------------------------

#
#-- ECHAM
#
res_atm=T63             # grid acronym (T21/T31/T42/T63/T85/T106/T127/T159)
vres_atm=47             # number of vertical levels (19/31/47/95)
atmvers=c2016a_180130o2 # atmosphere model version (used in executable name)
atm_out_filetype=2      # output file format:      1/2 = GRIB (def)/NETCDF
atm_out_ztype=0         # output file compression: 0/1/2 = NONE/SZIP(def)/2=ZIP
dt_write_atm=6          # time interval of output writing in hours
res_oce_pretend=GR15    # resolution of pretended ocean if alone_as_coupled 
nml_suf_echam=amip-LR   # namelist file suffix
lamip=true
iaero=5                 # time dependent aerosol forcing (3) incl.volcanic(5)
io3=4                   # time dependent ozone forcing
isolrad=1               # time dependent solar irradiance
ighg=1                  # read RCP greenhouse gases input data
lco2_scenario=true      # get CO2 concentrations from external ghg scenario
icfc=4
ich4=4
in2o=4
ico2=4
COSP=false                   # cosp diagnostic is switched of in mpiesm-1.0.00 #
#-- JSBACH
#
dynveg=true                    # calculate dynamic vegetation
dynveg_feedback=false          # activate feedback of dynamic vegetation on jsbach
ntiles=11                      # number of tiles
lcc_forcing_type=transitions   # scheme for landuse change (none,maps,transitions)
read_cpools=false              # true/false/force: read c-pools / fpc 
read_fpc=false                 #      if initialized / never / unconditionally
refyear=1976                   # initial data filename tag (cpools,fpc,jsbach etc)
nml_suf_jsbach=c5              # namelist_file_suffix
srf_out_filetype=GRIB          # output file format: GRIB/NETCDF
lctlibvers=nlct21.def
transition_scenario=historical # landuse transition scenario (only with
                               #      lcc_forcing_type=transitions)
                               #      historical / rcp45 / rcp85 / rcp26 / no
                               #      no: no transitions, harvest from refyear

alone_as_coupled=true          # use parameters as if coupled to the ocean

#
#-- if unexplained crashes; for different: 
#       - change value of enstdif (e.g. 1.0001) (ECHAM6 namelist dynctl)
#       - add lines if necessary but do not remove !
#
set_enstdif="[[ \$(echo \${startdate} | cut -c1-4) = YYYY ]] && enstdif=1.0001"

#-- Executable name as stored in .../bin

atmbin=${atmmod}_${atmvers}.x

#------------------------------------------------------------------------------
# End of component configuration
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
#   TIME CONTROL
#------------------------------------------------------------------------------
#
#-- calendar type: Available calendar options:
#     0   : No leap year (365 days per year)
#     1   : Gregorian (365/366 days per year)
#     n   : Equal months of "n" days (30 for 30 day months)

caltype=1

#
#-- initial and final date of the experiment
#   Format: YearMMDD[_hh[mm[ss]]], Year-MM-DD[_hh[:mm[:ss]]] or 
#           Year-MM-DD[Thh[:mm[:ss]]]
#   Note: The experiment will not stop within a run/chunk even if the
#         final date is reached.

initial_date=1850-01-01
#final_date=1982-01-01
final_date=1982-01-01
#
#-- duration of a run/chunk
#      Specify the length of each run in one of the below units.

integer nyear nmonth nday nhour nminute nsecond

nyear=0
nmonth=1
nday=0           # number of days per run
nhour=0          # number of hours per run
nminute=0        # number of minutes per run
nsecond=0        # number of seconds per run

#------------------------------------------------------------------------------
#   1.4 INITIAL SETTINGS
#------------------------------------------------------------------------------

#
#-- file and directory permissions of the output
#

export dir_permits=755
export file_permits=644

#------------------------------------------------------------------------------
#   MESSAGE PASSING
#------------------------------------------------------------------------------
#
#-- number of MPI-processors/openMP-threads
#

integer nproca_atm nprocb_atm nproma_atm nthreadatm

nproca_atm=16  # total number of MPI procs:
nprocb_atm=12   #    nproca_atm * nprocb_atm
nthreadatm=1   # number of openMP threads (overwrites OMP_NUM_THREADS)
nproma_atm=72

#------------------------------------------------------------------------------
#   MPI MESSAGE PASSING SPECIFICATIONS
#------------------------------------------------------------------------------


MPIBIN=$(which srun)

#
#-- number of processors used for the mpiexec
# 
integer nprocmpi

nprocmpi=0

#------------------------------------------------------------------------------
#   CONNECTION TO COMPILE SYSTEM
#------------------------------------------------------------------------------

#
#-- name of compiler (set according to Create_TASKS parameter specifications)

compiler=intel

#
#-- (symbolic) node name of the compile-server

compile_server=fram

#------------------------------------------------------------------------------
#   FILE SYSTEMS
#------------------------------------------------------------------------------
#
#-- home:  Permanent file system for the SCRIPTS on the COMPUTING HOST
#          (only needs to be specified if the tasks are NOT generated on the 
#          computing host)

workhome=/cluster/work/users/earnest/stercp_exp/t1SP_a9
export home=${workhome}

#
#-- archive_in:  Root directory of the LONG TERM INPUT data archive. It needs
#                to reside on the same machine as the output archive. This 
#                archive is intended for input data that is needed with 
#                several experiments, e.g. initial , forcing or restart files.
#                The parent-directory needs to exist before job submission.

export archive_in=/cluster/work/users/earnest/mpiexm_exp/restart_historical_mpiesm

#
#-- data:  Root directory of the SHORT TERM data server.
#          Model INPUT and OUTPUT will be read from/written to 
#          this file system of the computing host
#          The parent-directory needs to exist before job submission.

export data=${workhome}

#
#-- archive:  Root directory of the LONG TERM OUTPUT data archive:
#             a filesystem of the computing or of the remote archiving host. 
#             If ${archive} differs from ${data} model output will be saved
#             in ${archive} and removed from ${data}.
#             The parent-directory needs to exist before job submission.

export archive=${workhome}

#
#-- work:  Root directory for the temporary working directory
#             (for production runs use $TMPDIR on NEC)
#

work=${workhome}

#
#-- Path to the IMDI function directory
#
export fpath=/nird/home/earnest/models/MPI-ESM/mpiesm-1.echam6/Sources/util/running/functions
 
#
#-- <modelcomp>_bindir:   Directory of the model executables.
#
export atm_bindir=/nird/home/earnest/models/MPI-ESM/mpiesm-1.echam6/Sources/fram-intel/bin


#------------------------------------------------------------------------------
#   1.7 RESTART CONTROL
#------------------------------------------------------------------------------ 
#
#-- 'component'_restart: start from restart or initial files (climatology)
#         1  : start experiment from restart files for 'component'
#         0  : start experiment from initial conditions for 'component'
#      If the experiment starts from restart files you need to specify:
# 
#   'component'_age: the age of the restart file used in years
#   'component'_restart_file: filename of the restart file (including path)
#

odate=19781231; ndate=""                            # separate with hyphen
pexp=${expid}

atm_restart=1; atm_age=0
atm_restart_dir=${archive_in}/input/${atmmod}/${res_atm}/restart
atm_restart_file=${atm_restart_dir}/rerun_${pexp}_echam_${odate}${ndate}
atm_restart_co2=${atm_restart_dir}/rerun_${pexp}_co2_${odate}${ndate}
atm_restart_tracer=""
hd_restart_file=""

srf_restart_dir=${archive_in}/input/${srfmod}/${res_atm}/restart
srf_restart_jsbach=${srf_restart_dir}/rerun_${pexp}_jsbach_${odate}${ndate}
srf_restart_surf=${srf_restart_dir}/rerun_${pexp}_surf_${odate}${ndate}
srf_restart_veg=${srf_restart_dir}/rerun_${pexp}_veg_${odate}${ndate}

#------------------------------------------------------------------------------
#   PLATFORM DEPENDEND SPECIFICATIONS
#------------------------------------------------------------------------------

#
#-- Node name of archiving host  (empty if archiving on local file system)
#
export archiving_host=$HOST_ARCH

#------------------------------------------------------------------------------
#   UNIX COMMANDS
#------------------------------------------------------------------------------

export mkdir="mkdir -p"    # create a new directory
export cp="cp -p"          # copy without changing the time stamp
export ln="ln -s"          # sym/hard link: no err/err if non-exist. target
export rm=rm               # remove
export rtp="pftp"          # remote transfer protocol
export rtp_post="$rtp"     # transfer protocol to remote processing host
export put_archive=""      # command to put files to tape archive
export get_archive=""      # command to get files from tape archive
export gunzip="gzip -d"    # unzip a file that was zipped using gzip

export cdo=/sw/aix61/cdo-1.5.0/bin/cdo
export afterburner=/sw/aix61/after-4.6.3/bin/after
export grib=/sw/aix61/grib-1.4.5.1/bin/grib
export python=/sw/aix61/Python-2.6.4/bin/python

export ncdump=/sw/aix61/netcdf-4.1.1-rc1/bin/ncdump
export nco=/sw/aix53/nco-3.9.9-64bit/bin
#------------------------------------------------------------------------------
#   CONFIGURE MODEL INPUT
#------------------------------------------------------------------------------
#
#-- specify input files for ECHAM
#

aip=${archive_in}/input/${atmmod}
aipr=${archive_in}/input/${atmmod}/${res_atm}

atm_ifiles="\
get_file ${atmmod} input ${aipr}/${res_atm}\${res_oce}_VGRATCLIM.nc  unit.91;\
get_file ${atmmod} input ${aipr}/${res_atm}\${res_oce}_VLTCLIM.nc    unit.90;\
get_file ${atmmod} input ${aipr}/${res_atm}_TSLCLIM2.nc              unit.92;\
get_file ${atmmod} input ${aipr}/${res_atm}L${vres_atm}_jan_spec.nc  unit.23;\
get_file ${atmmod} input ${aipr}/${res_atm}\${res_oce}_jan_surf.nc   unit.24"

atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input  ${aip}/surrta_data                        rrtadata;\
get_file ${atmmod} input  ${aip}/rrtmg_lw.nc                     rrtmg_lw.nc;\
get_file ${atmmod} input  ${aip}/ECHAM6_CldOptProps.nc ECHAM6_CldOptProps.nc"

ozonedir=${aipr}/ozone2
atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${ozonedir}/${res_atm}_ozone_CMIP5_\${ym2}.nc ozon\${ym2};\
get_file ${atmmod} input ${ozonedir}/${res_atm}_ozone_CMIP5_\${ym1}.nc ozon\${ym1};\
get_file ${atmmod} input ${ozonedir}/${res_atm}_ozone_CMIP5_\${yr0}.nc ozon\${yr0};\
get_file ${atmmod} input ${ozonedir}/${res_atm}_ozone_CMIP5_\${yp1}.nc ozon\${yp1}"

aerodir=${aipr}/aero2
atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_fin_\${ym2}.nc aero_fine_\${ym2}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_fin_\${ym1}.nc aero_fine_\${ym1}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_fin_\${yr0}.nc aero_fine_\${yr0}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_fin_\${yp1}.nc aero_fine_\${yp1}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_coa.nc       aero_coarse_\${ym2}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_coa.nc       aero_coarse_\${ym1}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_coa.nc       aero_coarse_\${yr0}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_coa.nc       aero_coarse_\${yp1}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_lw_b16_coa.nc        aero_farir_\${ym2}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_lw_b16_coa.nc        aero_farir_\${ym1}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_lw_b16_coa.nc        aero_farir_\${yr0}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_lw_b16_coa.nc        aero_farir_\${yp1}.nc"

vaerodir=${aipr}/volcano_aerosols
atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_ir_${res_atm}_\${ym2}.nc strat_aerosol_ir_\${ym2}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_ir_${res_atm}_\${ym1}.nc strat_aerosol_ir_\${ym1}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_ir_${res_atm}_\${yr0}.nc strat_aerosol_ir_\${yr0}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_ir_${res_atm}_\${yp1}.nc strat_aerosol_ir_\${yp1}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_sw_${res_atm}_\${ym2}.nc strat_aerosol_sw_\${ym2}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_sw_${res_atm}_\${ym1}.nc strat_aerosol_sw_\${ym1}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_sw_${res_atm}_\${yr0}.nc strat_aerosol_sw_\${yr0}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_sw_${res_atm}_\${yp1}.nc strat_aerosol_sw_\${yp1}.nc"

amipdir=${aipr}/amip2
atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${amipdir}/${res_atm}_amip2sst_\${ym2}.nc sst\${ym2};\
get_file ${atmmod} input ${amipdir}/${res_atm}_amip2sst_\${ym1}.nc sst\${ym1};\
get_file ${atmmod} input ${amipdir}/${res_atm}_amip2sst_\${yr0}.nc sst\${yr0};\
get_file ${atmmod} input ${amipdir}/${res_atm}_amip2sst_\${yp1}.nc sst\${yp1};\
get_file ${atmmod} input ${amipdir}/${res_atm}_amip2sic_\${ym2}.nc ice\${ym2};\
get_file ${atmmod} input ${amipdir}/${res_atm}_amip2sic_\${ym1}.nc ice\${ym1};\
get_file ${atmmod} input ${amipdir}/${res_atm}_amip2sic_\${yr0}.nc ice\${yr0};\
get_file ${atmmod} input ${amipdir}/${res_atm}_amip2sic_\${yp1}.nc ice\${yp1}"

irraddir=${archive_in}/input/${atmmod}/solar_irradiance
atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${irraddir}/swflux_14band_\${ym2}.nc   swflux_\${ym2}.nc;\
get_file ${atmmod} input ${irraddir}/swflux_14band_\${ym1}.nc   swflux_\${ym1}.nc;\
get_file ${atmmod} input ${irraddir}/swflux_14band_\${yr0}.nc   swflux_\${yr0}.nc;\
get_file ${atmmod} input ${irraddir}/swflux_14band_\${yp1}.nc   swflux_\${yp1}.nc"

atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${aip}/greenhouse_rcp45.nc greenhouse_gases.nc"

#
#-- specify input files JSBACH 
#

grid=${res_atm}${res_oce_pretend}_${ntiles}tiles
sip=${archive_in}/input/${srfmod}
sipr=${sip}/\${res_srf}

srf_ifiles="\
get_file ${srfmod} input              lctlib_${lctlibvers}     lctlib.def;\
get_file ${srfmod} input ${sipr}/jsbach_${grid}_${refyear}.nc  jsbach.nc"

ludir=${archive_in}/input/${srfmod}/\${res_srf}/land_use
srf_ifiles=${srf_ifiles}";\
get_file ${srfmod} input ${ludir}/LUH_transitions_\${res_srf}_\${yr0}.nc landuseTransitions.\${yr0}.nc;\
get_file ${srfmod} input ${ludir}/LUH_transitions_\${res_srf}_\${ym1}.nc landuseTransitions.\${ym1}.nc;\
get_file ${srfmod} input ${ludir}/LUH_harvest_\${res_srf}_\${yr0}.nc         landuseHarvest.\${yr0}.nc;\
get_file ${srfmod} input ${ludir}/LUH_harvest_\${res_srf}_\${ym1}.nc         landuseHarvest.\${ym1}.nc"

###############################################################################
#
#      END OF THE USER INTERFACE
#
###############################################################################

set -e
#------------------------------------------------------------------------------
#  Complete setup
#------------------------------------------------------------------------------

#
#-- get CMIP5 MPI-ESM model acronym
#
res_mod=$(echo $expid | cut -f2 -d"-")

#
#-- assumed resolution of partner model
#
res_oce=""; [[ ${alone_as_coupled} = true ]] && res_oce=${res_oce_pretend}

[[ ! "$res_srf"       = "" ]] || res_srf=${res_atm}
[[ ! "$srf_restart"   = "" ]] || srf_restart=${atm_restart}
[[ ! "$srf_out_ztype" = "" ]] || srf_out_ztype="${atm_out_ztype}"

#
#-- Parameters for ECHAM
#
nadt=600

#
#-- deactivation of the HD model (not supported in stand alone ECHAM runs)
#
hd=false

#
#-- Executable name for launching etc.
#
atmexec=${atmmod}

atm_src_revision=$(echo $atmbin | cut -f3 -d"_" | cut -c2-5)

#
# Number of MPI-processors/openMP-threads
# ---------------------------------------

integer ntproc nprocatm

nprocatm=nproca_atm*nprocb_atm  # total number of atm. MPI processes

# total number of MPI processes
ntproc=nprocatm+nprocmpi

#------------------------------------------------------------------------------
#   Definition of the functions 
#------------------------------------------------------------------------------

export PATH=${fpath}:$PATH 

. function_check_size
. function_check_codes
. function_dbfill
. function_generate_tarfile
. function_get_file
. function_get_model_resolution
. function_get_tarfile
. function_make_directories
. function_put_file
. function_plot_file
. function_pperror

#------------------------------------------------------------------------------
#   Job specification
#------------------------------------------------------------------------------
qsub="qsub"        # submit command

if [ "${qsub}" = "qsub" ]; then
  jobdir=${home}/${expid}/scripts       # directory of this script
  cd ${jobdir}
  jobid=${expid}
  job=${jobid}.run
else
  jobdir=`dirname $0`
  cd ${jobdir}
  jobdir=`pwd`
  jobid=${expid}
  job=`basename $0`
fi


print " - job name         \t${job}"
print " - job id           \t${jobid}\n - job directory    \t${jobdir}\n"


#------------------------------------------------------------------------------
#
#     3. CALENDAR
#
#------------------------------------------------------------------------------
#
#-- calculate length of the run in seconds for the case that (optionally)
#   the length of run is given in number of model steps of any of the models.
#
if   [ "${nstep_atm}" -ne 0 ] && [ "${nstep_atm}" -ne "" ]; then
  (( nsecond = nstep_atm * nadt ))
elif [ "${nstep_oce}" -ne 0 ] && [ "${nstep_oce}" -ne "" ]; then
  (( nsecond = nstep_oce * nodt ))
elif [ "${nstep_che}" -ne 0 ] && [ "${nstep_che}" -ne "" ]; then
  (( nsecond = nstep_che * ncdt ))
elif [ "${nstep_srf}" -ne 0 ] && [ "${nstep_srf}" -ne "" ]; then
  (( nsecond = nstep_srf * nsdt ))
fi

#
#-- find out smallest time unit in inidate and job length
#
inidate=`format_date -- ${initial_date}`   # transform to format (YearMMDD_hhmmss)
findate=`format_date -- ${final_date}`

nwords=$(format_date -f4 -- ${inidate} | wc -w) 
if [ ${nwords} -eq 6 ] || [ ${nsecond} -ne 0 ]; then
  inidate=$(format_date -s -- ${inidate})
  findate=$(format_date -s -- ${final_date})
elif [ ${nwords} -eq 5 ] || [ ${nminute} -ne 0 ]; then
  inidate=$(format_date -m -- ${inidate})
  findate=$(format_date -m -- ${final_date})
elif [ ${nwords} -eq 4 ] || [ ${nhour} -ne 0 ]; then
  inidate=$(format_date -h  -- ${inidate})
  findate=$(format_date -h  -- ${final_date})
fi

#
#-- date of this run
#

cd ${jobdir}
space_error="no"

datefmt='%a %b %d %H:%M:%S %Z %Y'  # date format for expid.log file

if [ ! -f ${expid}.date ]; then

  startdate=${inidate}
  jobnum=1
  rm -f ${expid}.log
  print "$(date +"${datefmt}") :  Beginning of Experiment ${expid}" > ${expid}.log.new || { 
      space_error="yes"; print "Could not create ${expid}.log"; 
  }
else
  read startdate jobnum < ${expid}.date
  cp ${expid}.log ${expid}.log.new || { 
    space_error="yes"; print "Could not save ${expid}.log"; 
  }
fi

print "$(date +"${datefmt}") :  ${jobnum} ${startdate} ${jobid}  - start" >> ${expid}.log.new || { 
  space_error="yes"; print "Could not append to ${expid}.log"; 
}
if [ "${space_error}" = "no" ]; then
  mv ${expid}.log.new ${expid}.log
else
  print "  |- ERROR: No disk space left or quota exceeded?"
  exit 1
fi

integer scrcap
line=$(df -k $data | tail -1)
scrfs=${line##* }
line=${line%%\%*} ;scrcap=${line##* }

if (( scrcap > 99 )); then
  print "  |- ERROR: Less than 1% disc space left on filesystem $scrfs, where your"
  print "  |    workshare data=$data is mounted. Please clean up before you continue !"
  exit 1
fi

nextdate=$(calc_date plus -c${caltype} -Y${nyear} -M${nmonth} -D${nday} -h${nhour} -m${nminute} -s${nsecond} -- ${startdate})

print " |+ Time integration and run periode"
print "  |- Initial date of the experiment\t${inidate}"
print "  |- Final date of the experiment\t${findate}"
print "   |- Beginning of this run    \t ${startdate}"
print "   |- Beginning of the next run\t ${nextdate}\n"

nudging_startdate=`format_date -f4 -s -- ${startdate} | tr " " ,`
nudging_enddate=`format_date -f4 -s -- ${nextdate} | tr " " ,`

#------------------------------------------------------------------------------
#   Directory definitions
#------------------------------------------------------------------------------
exphome=${data}/${expid}          # Root directory of the experiment (data)

[ ${host_rem:-NotSet} = NotSet ] || {
  if [ "$(hostname)" = "${host_rem%%.*}" ] ; then 
   exphome=${path_rem:-""}/${expid}   # the above, if processing is remote
  fi
  }
export bindir=${archive}/${expid}/bin      # Directory of the executables
mkdir -p ${bindir}
cp -rfv ${atm_bindir}/*${atmvers}*  ${bindir}                #   */
export inpdir=${exphome}/input    # Directory of the input files
export restdir=${archive}/${expid}/restart # Directory of the restart files
export outdir=${archive}/${expid}/outdata  # Directory of the output data files
export logdir=${archive}/${expid}/log      # Directory of the log data files
mkdir -p ${logdir}
export postdir=${archive}/${expid}/post    # Directory for post-processed data

if [ ${jobnum} = 1 ];then
  make_directories $task "${atmmod},${srfmod},${ocemod},${bgcmod},${coupler}"
  if [ "${task}" = "RUN" ]; then
    [[ "${groupwrite:-no}" = "no" ]] || {
       chmod g+wx ${data} ${exphome} ${bindir} ${inpdir} ${logdir}       \
         ${restdir} ${restdir}/${atmmod} ${restdir}/${srfmod}            \
         ${restdir}/${ocemod} ${restdir}/${bgcmod} ${restdir}/${coupler} \
         ${outdir} ${outdir}/${atmmod} ${outdir}/${srfmod}               \
         ${outdir}/${ocemod} ${outdir}/${bgcmod} ${outdir}/${coupler} || true; }
  fi
fi

#------------------------------------------------------------------------------
#
#     save log file of the previous run
#
#------------------------------------------------------------------------------


if [ ${jobnum} != 1 ]; then
    # find out the id of the last run
    loginfo=$(get_logpid -d ${startdate} -f ${jobdir}/${expid}.log)                
    previd=${loginfo%[ ]*}
    if [ "${previd}" = "${expid}" ] || [ -z "${previd}" ]; then 
      printf "\t|- WARNING : Job id of the previous run can not determined."
      printf "\t|    Job maybe interactively submitted.\n"
    else
	date=${loginfo#*[ ]}
        logfile=my_${job}.o${previd}
	if [ ! -f ${jobdir}/${logfile} ] && \
           [ ! -f ${logdir}/${job}_${date}.o${previd} ]; then
	  printf "\tAwaiting the log file of the previous run: ${logfile}...\n"
	  sleep 30
	fi
	if [ -f ${jobdir}/${logfile} ]; then
	    mv ${jobdir}/${logfile} ${logdir}/${job}_${date}.o${previd}

        elif [ ! -f ${logdir}/${job}_${date}.o${previd} ]; then
            printf "\t%s%s\n" "WARNING : No logfile of the previous run " \
                   "(job no $(( jobnum - 1 )) ) - continue"
        fi
    fi
fi

#------------------------------------------------------------------------------
#   PRE - PROCESSING : check working directory, clean, and cd
#------------------------------------------------------------------------------

cd ${work}

[[ -d ${expid}/work ]] || mkdir -p ${expid}/work
[[ "${groupwrite:-no}" = "no" ]] ||  {  
 chmod g+wx  ${expid}/work || true; }

cd ${expid}/work;  rm -rf *

printf "\n |- Temporary working directory     \t$(pwd)\n"
printf   " |- Data workshare on compute node  \t$data/$expid\n\n"

#------------------------------------------------------------------------------
#     PRE - PROCESSING : provide executables
#------------------------------------------------------------------------------

#
# for CMIP5 experiments the executables are taken from ${<modelcomp>_bindir}/bin
#

${ln} ${atm_bindir}/${atmbin} ${atmexec}


#------------------------------------------------------------------------------
#     PRE - PROCESSING : provide the input data 
#------------------------------------------------------------------------------

printf " |- Get input and restart data\n"

#
#-- input files for ECHAM
#

typeset -Z4 yr0 yp1 ym1 ym2
yr0=$(echo ${startdate} | cut -c1-4)
(( yp1 = yr0 + 1 )); (( ym1 = yr0 - 1 )); (( ym2 = yr0 - 2 ))

eval ${atm_ifiles}


#-- (de)activate simulator output (isccp etc.) according to CMIP5/CFMIP request
#   note: care must be taken that the year before has been
#         run with locosp=T if locosp=true below. This may be a problem when
#         the restart files are generated by another experiment.
#   off: difference [years] between start year of piControl and 1pctCO2 (or abrupt4xCO2)
#
. c5_cosp_request
c5_cosp_request $(echo ${startdate} | cut -c1-4) $expid locosp ${off:-""}
prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
prevyear=$(format_date -f4 -- ${prevdate} | cut -f1 -d" ")
c5_cosp_request $prevyear                        $expid locosp_prev ${off:-0}

#-- No COSP files generated for model revisions less than 4871
[[ "${atm_src_revision}" -ge 4871 ]] || locosp=false

#-- No COSP files generated for mpiesm-1.0.00
if [[ "${COSP}" = false ]]; then
  locosp=false
fi



#-- COSP restart files have to be generated with locosp=T

[[ $locosp = true && ${jobnum} = 1 ]] && {
    printf "%40s%s\n%s\n" "ATTENTION: potential ERROR: Ensure that the restart " \
                    "files have been generated with locosp=T." \
                    "If so, comment out the exit below."
    exit 1; 
 }

if [[ $locosp = true  || $locosp = T ]]; then
tdiag="tdiag"
 else
tdiag=""
fi

#preparing nudging data 

ln -sf /cluster/work/users/earnest/stercp_exp/t1SP_a9/SP_nudging/Data/ECHAM6/198201/ndg_* ${archive}/${expid}/work/

#
#-- restart files for ECHAM
#
# restart files for additional CFMIP diagnostics
if [[ $locosp = true || $locosp = T  ]]; then
 tdiagmrest=rerun_${expid}_tdiagm
 tdiagm_restart_file=${atm_restart_dir}/rerun_${pexp}_tdiagm_${odate}${ndate}
 cosprest=rerun_${expid}_cosp 
fi


if [ ${jobnum} != 1 ]; then
  prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
  get_file ${atmmod}  restart  rerun_${expid}_echam_${prevdate} rerun_${expid}_echam
  get_file ${atmmod}  restart  rerun_${expid}_echam_${prevdate} rerun_${expid}_nudg
  if [ ${hd:-false} = true ]; then
    get_file ${atmmod} restart rerun_${expid}_hd_${prevdate}.nc hdrestart.nc
  fi
  if [[ ${locosp:-false} = true ]]; then
   get_file ${atmmod}  restart  rerun_${expid}_tdiagm_${prevdate} rerun_${expid}_tdiagm
  fi
  if [[ ${locosp:-false} = T ]]; then
   \cp rerun_${expid}_echam ${tdiagmrest}
  fi
  if [ "${srfmod}" = "jsbach" ]; then
    get_file ${atmmod} restart  rerun_${expid}_co2_${prevdate} rerun_${expid}_co2
  fi
  if [ "${lco2}" = "true" ]; then
    get_file ${atmmod} restart  rerun_${expid}_tracer_${prevdate} \
                                rerun_${expid}_tracer
  fi
elif [ ${atm_restart} = 1 ] ; then
  \cp ${atm_restart_file}    rerun_${expid}_echam
  if [ ${hd:-false} = true ]; then
    \cp ${hd_restart_file}   hdrestart.nc
  fi
  if [ "${srfmod}" = "jsbach" ]; then
    \cp ${atm_restart_co2}     rerun_${expid}_co2
  fi
  if [ "${lco2}" = "true" ]; then
    \cp ${atm_restart_tracer}  rerun_${expid}_tracer
  fi
  if [[ $locosp = true || $locosp = T ]]; then
   if [[ -e ${tdiagm_restart_file} ]]; then
    \cp ${tdiagm_restart_file} rerun_${expid}_tdiagm
   else
     echo "WARNING:  generic restart file for tdiagm"
     if [[ -e  rerun_${expid}_echam  ]]; then
        \cp rerun_${expid}_echam ${tdiagmrest}
     fi
   fi
  fi
fi
if [[ $locosp = true  || $locosp = T  ]]; then
 if [[ -e ./rerun_${expid}_echam ]]; then
  \cp rerun_${expid}_echam ${cosprest}
 fi 
fi
#
#-- input files for JSBACH
#

typeset -Z4 yr0 yp1 ym1 ym2
yr0=$(echo ${startdate} | cut -c1-4)
(( yp1 = yr0 + 1 )); (( ym1 = yr0 - 1 )); (( ym2 = yr0 - 2 ))

eval ${srf_ifiles}

#
#-- restart files for JSBACH
#

prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
if [ ${jobnum} != 1 ]; then
  get_file ${srfmod}  restart  rerun_${expid}_jsbach_${prevdate} rerun_${expid}_jsbach
  get_file ${srfmod}  restart  rerun_${expid}_veg_${prevdate}    rerun_${expid}_veg
  if [ ${atmmod:-NotSet} = NotSet ]; then
    get_file ${srfmod}  restart  rerun_${expid}_forcing_${prevdate} rerun_${expid}_forcing
    get_file ${srfmod}  restart  rerun_${expid}_driving_${prevdate} rerun_${expid}_driving
  else
    get_file ${srfmod}  restart  rerun_${expid}_surf_${prevdate} rerun_${expid}_surf
  fi
elif [ ${srf_restart} = 1 ] ; then
  \cp ${srf_restart_jsbach}  rerun_${expid}_jsbach
  \cp ${srf_restart_veg}     rerun_${expid}_veg
  if [ ${atmmod:-NotSet} = NotSet ]; then
    \cp ${srf_restart_forcing} rerun_${expid}_forcing
    \cp ${srf_restart_driving} rerun_${expid}_driving
  else
    \cp ${srf_restart_surf}    rerun_${expid}_surf
  fi
fi

#------------------------------------------------------------------------------
#    PRE - PROCESSING : provide and update configuration files (namelists etc.)
#------------------------------------------------------------------------------

printf "\n%s\n" " |- Provide configuration files (namelists, XML, etc.)"

#------------------------------------------------------------------------------
#-- Namelist ECHAM
#

#
#-- set switch for latitude dependent sources of gravity waves (QBO)

if [[ $vres_atm -lt 95 ]]; then
  lrmscon_lat=false
else
  lrmscon_lat=true
fi


#
#-- resumed or initial run?
#
if [[ ${jobnum} = 1 && ${atm_restart} = 0 ]]; then
  rerun=.FALSE.
else
  rerun=.TRUE.
fi

#
#-- coupled or stand-alone run?
#

# initial date of the experiment (with coupled runs: one timestep before
#    midnight)
# Initialisation of the echam time manager can take a long time if the current
# date is far from the initial date of the experiment. To improve this, we set
# the year in dt_start just one year befor the the current date.
# (Setting dt_start to the current date would lead to echam re-initialization!)
#    Note that events that do not occur on a yearly basis will not be treated
#    correctly!

if [[ "${ocemod:-""}" = "" ]]; then
 # stand alone echam
 lcouple=false
 date=$(calc_date minus -c${caltype} -Y${atm_age} -s${nadt} -- ${inidate})
 year=$(format_date -f4 -- ${inidate} | cut -f1 -d" ")
 month_day_time=$(format_date -f4 -s -- ${date} | cut -f2- -d" ")
 dt_year=$(format_date -f4 -- ${date} | cut -f1 -d" ")
 dt_date="${dt_year} ${month_day_time}"
 date="${year} ${month_day_time}"
 dt_start=$(echo ${dt_date} | tr " " ,)
 [[ ${atm_restart} = 0 ]] || dt_start="0000,00,00,00,00,00"
else
 # echam coupled to ocean
 getoff=0
 putoff=-$nadt
 na2ocsteps=$(expr $dta2o / $nadt)
 no2acsteps=$(expr $dto2a / $nadt)
 getocean="$no2acsteps,'steps','exact',$getoff"
 putocean="$na2ocsteps,'steps','exact',$putoff"
 lcouple=true
 date=`calc_date minus -c${caltype} -Y${atm_age} -s${nadt} -- ${inidate}`
 year=`format_date -f4 -- ${startdate} | cut -f1 -d" "`
 if [ ${rerun} = .TRUE. ]; then
   (( year = year - 2 ))
 fi
 if [ ${rerun} = .FALSE. ]; then
   (( year = year - 1 ))
 fi
 month_day_time=$(format_date -f4 -s -- ${date} | cut -f2- -d" ")
 date="${year} ${month_day_time}"
 dt_start=$(echo ${date} | tr " " ,)
fi

#
#-- end date of the run
#
dt_stop=`format_date -f4 -s -- ${nextdate} | tr " " ,`

#
#-- rerun interval
#
if [ ${nmonth} -ne 0 ]; then
  (( nm = 12 * nyear + nmonth )) 
  put_rerun="${nm},'months','last',0"
elif [ ${nyear} -ne 0 ]; then
  put_rerun="${nyear},'years','last',0" 
elif [ ${nday} -ne 0 ]; then
  put_rerun="${nday},'days','last',0"
fi

#
#  modifying namelist parameters during experiment
#  1) for setting disturbance parameter (crashes; realisation)
#  2) for modifying orbital parameters
#
eval $set_enstdif || enstdif=1.0

cat -> namelist.echam << EOF
&parctl
  NPROCA       = ${nproca_atm}
  NPROCB       = ${nprocb_atm}
/
&runctl
  LTIMER         = .${ltimer:-false}.
  LRESUME        = ${rerun}
  OUT_DATAPATH   = './' 
  OUT_EXPNAME    = '${expid}'
  OUT_FILETYPE   = ${atm_out_filetype}
  OUT_ZTYPE      = ${atm_out_ztype}
  RERUN_FILETYPE = 4
  LAMIP          = ${lamip:-.false.}
  DT_START       = ${dt_start}
  DT_STOP        = ${dt_stop}
  DELTA_TIME     = ${nadt}.
  PUTDATA        = ${dt_write_atm},'hours','first',0
  PUTRERUN       = ${put_rerun}
  TRIGFILES      = 1,'months','first',0
  lnudge         = .true.
  LIPCC          = .true.
  NO_CYCLES      = ${no_cycles:-1}
  LMIDATM        = .true.
  LDEBUGEV       = .${ldebugev:-false}.
  LCOUPLE_CO2    = .${lcouple_co2:-false}.
/
&dynctl
  ENSTDIF        = ${enstdif:-1.0}
/
&physctl
  LCOVER       = .false.
/
&gwsctl 
  LRMSCON_LAT  = .${lrmscon_lat:-false}. 
/
&submodelctl
  LCO2         = .${lco2:-false}.
  LMETHOX      = .true.
  LTRANSDIAG   = .true.
/
&radctl
  IAERO        = ${iaero:-2}
  IO3          = ${io3:-3}
  IGHG         = ${ighg:-0}
  ISOLRAD      = ${isolrad:-3}
  ICFC         = ${icfc:-2}
  ICH4         = ${ich4:-3}
  IN2O         = ${in2o:-3}
  ICO2         = ${ico2:-2}
/
&cospctl
 LOCOSP        = .${locosp:-false}.
/
&co2ctl
 lco2_scenario = .${lco2_scenario:-false}.
/
&NDGCTL
  DT_NUDG_START   = ${nudging_startdate}
  DT_NUDG_STOP    = ${nudging_enddate}
  LNUDGDBX        = .false.
  LNUDGINI        = .false.
  inudgformat   = 2
  NUDGLMIN      = 1
  NUDGLMAX      = 47
  NUDGSMIN      = 0
  NUDGSMAX      = 31
  LNUDGIMP      = .true.
  NUDGD         = 31*0.579
  NUDGT         = 31*1.16
  NUDGV         = 31*4.63
  NUDGP         = 1.16
  LTINTLIN        = .false.
  LDAMPLIN        = .true.
  NUDGDAMP        = 1.
  ndg_file_nc    = "ndg_%y4%m2.nc"
/
 
EOF

# NOTE: The namelist file is created from 
#         nml_echam6_amip-LR
#       in directory .../util/running/adjunct_files/echam6


if [[ $locosp = true  || $locosp = T ]]; then
#
#  write diag.nml for CFMIP tendency output
#
cat ->  tdiag.nml  << EOF
&MVCTL
PUTMEAN = 1,'days','first',0
meannam = 'dqdt_vdiff','dqdt_cucall','dqdt_cloud','dtdt_vdiff','dtdt_cucall','dtdt_cloud','dtdt_rheat_sw','dtdt_rheat_lw','dtdt_hines','dtdt_sso','aps'
/
EOF
fi

echo "* ----------------------------------------------------------------------"
echo "* Namelist of ECHAM: namelist.echam"
echo "* ----------------------------------------------------------------------"
cat namelist.echam
echo "* ----------------------------------------------------------------------"
echo "*    end of namelist.echam"
echo "* ----------------------------------------------------------------------"
echo ""

#
#-- Namelist JSBACH
#

#
# read_fpc / read_cpools
#   false: never read C-pools / fractional plant cover from file
#   true : read C-pools/fpc from file only when the experiment is initialized
#          (jobnum=1 && srf_restart=0) 
#   force: read C-pools during a running experiment to overwrite the values
#          from the restart file (jobnum>1 || srf_restart=1)

if [[ ${jobnum} != 1 || ${srf_restart} = 1 ]] ; then
  [[ ${read_cpools:=false} = true  ]] && read_cpools=false
  [[ ${read_fpc:=false}    = true  ]] && read_fpc=false
fi
[[ ${read_cpools:=false} = force ]] && read_cpools=true
[[ ${read_fpc:=false}    = force ]] && read_fpc=true

init_running_means=false
if [[ ${dynveg} = true && ${srf_restart} = 0 \
   && $(time_between ${inidate} ${startdate} months) -eq 12 ]]; then
  init_running_means=true
fi


cat -> namelist.jsbach <<EOF
&jsbach_ctl
  STANDALONE         = .false.
  NTILES             = ${ntiles}
  USE_BETHY          = .true.
  USE_PHENOLOGY      = .true.
  USE_ALBEDO         = .true.
  USE_DYNVEG         = .${dynveg:-false}.
  WITH_NITROGEN      = .false.
  LCC_FORCING_TYPE   = "${lcc_forcing_type:-none}"
  FILE_TYPE          = "${srf_out_filetype}"
  LPOST_ECHAM        = .${lpost_echam:-false}.
  DEBUG              = .false.
  TEST_CCONSERVATION = .true.
  READ_COVER_FRACT   = .${read_cover_fract:-false}.
/
&cbalance_ctl
  READ_CPOOLS = .${read_cpools:-false}.
  READ_NPOOLS = .${read_npools:-false}.
  READ_NDEPO  = .${read_ndepo:-false}.
/
&dynveg_ctl
  READ_FPC           = .${read_fpc:-false}.
  DYNVEG_FEEDBACK    = .${dynveg_feedback:-true}.
/
&climbuf_ctl
  INIT_RUNNING_MEANS = .${init_running_means:-false}.
/
EOF

# NOTE: The namelist file is created from 
#         nml_jsbach_c5
#       in directory .../util/running/adjunct_files/jsbach

echo "* ----------------------------------------------------------------------"
echo "* Namelist of JSBACH: namelist.jsbach"
echo "* ----------------------------------------------------------------------"
cat namelist.jsbach
echo "* ----------------------------------------------------------------------"
echo "*    end of namelist.jsbach"
echo "* ----------------------------------------------------------------------"
echo ""

#------------------------------------------------------------------------------
#
#     5. LAUNCHING THE MODEL
#
#------------------------------------------------------------------------------

printf "List of files in working directory \n$(pwd) \nat $(date):\n"; ls -al
# Create a test file for script .../functions/save_file
mv ${jobdir}/out_* ${logdir} || echo "no old log files. "

echo "The date of the output files is compared to the date of this file" \
	  > reference_file

###############################################################################
#
# Environment variables for the Parallel Operating Env. (poe)
#  (see http://www.dkrz.de/dkrz/services/P6_docs/P6-howto8_en_US.html
#    for details)
#
###############################################################################
#
# debug options
#

export MPICH_MAX_SHORT_MSG_SIZE=960000 # default is 128000 bytes
export MPICH_PTL_UNEX_EVENTS=90000 # default is  90000 (unexpected recv queue size)
export MPICH_UNEX_BUFFER_SIZE=600M # default is    60M (unexpected short msgs buff size)
#setenv MPICH_MSGS_PER_PROC      160000 # default is  32768
export MPICH_MSGS_PER_PROC=32768 # default is  32768
export MPICH_PTL_SEND_CREDITS=-1

export MPICH_ENV_DISPLAY=1
export MPICH_VERSION_DISPLAY=1

# These environment variables were suggested by Helen He to help get around compiler issues
# with pgi9
export MALLOC_MMAP_MAX_=0
export MALLOC_TRIM_THRESHOLD_=536870912

# The environment variables below produce corefiles and maybe (?) should be
# moved to DEBUG mode at some point
export MPICH_DBMASK=0x200
export decfort_dump_flag=Y
#limit coredumpsize unlimited

# The environment variable below increase the stack size, which is necessary for
# CICE to run threaded on this machine.  
#setenv KMP_STACKSIZE 64M


#
# OpenMP: number of threads for program 
#                     (overwritten by omp_set_num_threads function )
#
OMP_NUM_THREADS=${OMP_NUM_THREADS:-1}; export OMP_NUM_THREADS

ulimit -c 0   # size of core dumps, in number of 512-byte blocks

#
###############################################################################

###############################################################################

#
#-- Launch the parallel job
#

export ECHAM6_THREADS=${nthreadatm:-1}


cd ${work}/${expid}/work
set -ex
export LID="`date +%y%m%d_%H%M%S`"
outlogfile=${jobdir}/out_${expid}_log_$LID
outerrfile=${jobdir}/out_${expid}_err_$LID


printf "\n%s\n" " |---------------------------------------------------------|"
printf "%s\n"   " |- Model launched at \$(date)                              "
printf "%s\n\n" " |---------------------------------------------------------|"


    rm -f mpmd.lst
    n=0
    (( n2 = n + nprocatm -1 ))
    echo "${n1}-${n} ./${atmexec}" >> mpmd.lst

    paffopt=" -n ${nprocatm} "
 time  ${MPIBIN} ${paffopt} ./${atmexec}  1> ${outlogfile} 2> ${outerrfile}  || {
 printf "\n%s\n" " |---------------------------------------------------------|"
 printf "%s\n"   " |- ERROR in model integration                              "
 printf "%s\n"   " |- Model run aborted at \$(date)                           "
 printf "%s\n\n" " |---------------------------------------------------------|"
  ls -lta
  exit 1
 }

printf "\n%s\n" " |---------------------------------------------------------|"
printf "%s\n"   " |- Model run completed at \$(date)                         "
printf "%s\n\n" " |---------------------------------------------------------|"



#logfile=${jobdir}/${jobname_mod}.o${jobnum}; touch $logfile

#rm -f ERROR.ctl; grep ERROR $logfile > ERROR.ctl 2>/dev/null || status=$?
#cat $logfile; rm $logfile; pwd; ls -lat

if [[ -s ERROR.ctl ]]; then
  printf "%s\n%s\n" "An ERROR has been detected during model integration." \
                    "   ==> The script is stopped."
  RUN_status=1; wait; exit 1
else
#
#-- Generate profiling protocol
#
if [ -f  *.${atmexec} ]; then
  echo 'Profiling '${atmexec}' ...'
  ${cp} *.${atmexec} ${logdir}/${atmexec}.mon.out
  ${cp} *.${atmexec} mon.out
  prof ${atmexec}
fi

profile=no
if [[ "${profile}" = "yes" ]]; then
  mv ${atmexec}.viz ${atmexec}_${startyear}.viz
  mv ${atmexec}.hpm ${atmexec}_${startyear}.hpm
  cat namelist.echam6 >>  ${atmexec}_${startyear}.hpm
  mpi_profile_list=$(ls mpi_profile.*)
  for file in ${mpi_profile_list}; do
    suffix=${file#mpi_profile.}
    mv ${file} mpi_profile_${startyear}.${suffix}
    mv mpi_profile_${suffix}.viz mpi_profile_${startyear}.${suffix}.viz
  done
  mv single_trace single_trace_${startyear}
fi
fi  


###############################################################################
#
# Start raw output saving ...
#
###############################################################################

#-- Definition of some time variables

# enddate:      last day of this run
# prevdate:     last day of the previous run 
# startyear:    year at the beginning of this run
# prevyear:     year at the last day of the previous run
# prevdecade:   decade at the last day of the previous run
# previd:       job-id of the previous run (from expid.log)

enddate=$(calc_date minus -c${caltype} -D1 -- ${nextdate})
prevdate=$(calc_date minus -c${caltype} -D1 -- ${startdate})
startyear=$(format_date -f4 -- ${startdate} | cut -f1 -d" ")
prevyear=$(format_date -f4 -- ${prevdate} | cut -f1 -d" ")
prevdecade=${prevyear%?}

if [[ -r ${jobdir}/${expid}.log ]];then
  loginfo=$(get_logpid -d ${startdate} -f ${jobdir}/${expid}.log)
  if [[ -n ${loginfo} ]];then
    previd=${loginfo%[ ]*}
    prevstart=${loginfo#*[ ]}
  else
    printf "%s%s\n" "   |- WARNING : Can not find message for ${startdate}" \
                    " in" "      ${jobdir}/${expid}.log"
    previd=
    prevstart=${startdate}
  fi
else
  printf "   |- WARNING : Can not access log file \n\t\t${jobdir}/${expid}.log\n"
  printf "   |            log files of previous run can not be archived !\n\n"
fi

###############################################################################
#
#  Save output of ECHAM
#
###############################################################################

wait
printf "\n%s\n\t\t%s\n\t\t%s\n\n" "+++++ Save ECHAM output and restart files" \
       " from   ${work}/'expid'/work" " to     $data/'expid'"

suff=.grb; [[ "${atm_out_ztype}" = "1" ]] && suff=.sz
cd ${work}/${expid}/work; wait

SAVE_status=${SAVE_status:="0"}

#-- raw diagnostic output, code lists (first run only), and restart files 

#-- ECHAM output streams
substreams="echam co2" # default streams
[[ "${lco2}" = "true" ]] && substreams="${substreams} tracer" # tracer
#- additional CFMIP output
if [[ ${locosp:-false} = true ]]; then # Warning: no saving if locosp=T !
  substreams="${substreams} tdiagm tdiag cfdiag"
fi

for substream in ${substreams};do
  date=${startdate}
  while [[ $(later_date -- ${date} ${enddate}) = ${enddate} ]]; do
    year=$(format_date  -f4 -- ${date} | cut -f1 -d" ")
    month=$(format_date -f4 -- ${date} | cut -f2 -d" ")
    day=$(format_date   -f4 -- ${date} | cut -f3 -d" ")
    ym=${year}${month}
    if [ -r ${expid}_${ym}.${day}_${substream} ]; then
      save_file ${atmmod} output ${expid}_${ym}.${day}_${substream} \
                                 ${expid}_${atmmod}_${substream}_${ym}${suff} &
    else
      SAVE_status=${SAVE_status}/echam:${substream}${month}
    fi
    #-- hydrology output files
    if [ -r ${expid}_${ym}.${day}_hd_higres.nc ]; then
      save_file ${atmmod} output ${expid}_${year}01.${day}_hd_higres.nc \
                                 ${expmod}_hd_higres_${startdate}.nc &
    fi
    date=$(calc_date plus -c${caltype} -M1 -- ${date})
  done # months
  if [[ ${jobnum} = 1 ]]; then
    if [ -r ${expid}_${startyear}01.${day}_${substream}.codes ]; then
      save_file ${atmmod} log ${expid}_${startyear}01.${day}_${substream}.codes \
                              ${expid}_${atmmod}_${substream}.codes &
    else
      SAVE_status=${SAVE_status}/echam:codes:${substream}
    fi
  fi
  if [[ -r rerun_${expid}_${substream} ]]; then
    save_file ${atmmod} restart rerun_${expid}_${substream} \
                                rerun_${expid}_${substream}_${enddate} &
  else
    if [[ ${substream} != tdiag ]] && [[ ${substream} != cfdiag ]];then 
      SAVE_status=${SAVE_status}/echam:rerun:${substream}
    fi
  fi
done # substreams

#-- Additional CFMIP output (cfSites)
if [[ ${locosp:-false} = true ]]; then     # Warning: no saving if locosp=T !
  date=${startdate}
  while [[ $(later_date -- ${date} ${enddate}) = ${enddate} ]]; do
    year=$(format_date  -f4 -- ${date} | cut -f1 -d" ")
    month=$(format_date -f4 -- ${date} | cut -f2 -d" ")
    day=$(format_date   -f4 -- ${date} | cut -f3 -d" ")
    ym=${year}${month}
    if [[ -r ${expid}_${ym}.${day}_cfSites0000 ]]; then
      tar czvf ${expid}_${ym}.${day}_cfSitesAll.tar.gz ${expid}_${ym}.${day}_cfSites????  
      if [[ -r  ${expid}_${ym}.${day}_cfSitesAll.tar.gz  ]]; then
       save_file ${atmmod}  output  ${expid}_${ym}.${day}_cfSitesAll.tar.gz  ${expid}_${atmmod}_cfSitesAll_${ym}.tar.gz
      else
        SAVE_status=${SAVE_status}/echam:cfSitesAll${month}
      fi
    fi

  date=$(calc_date plus -c${caltype} -M1 -- ${date})
 done # months
fi  # locosp

#-- CFMIP code files 
if [[ ${locosp_prev:-false} = T ]]; then  
  cfsubstreams="tdiag tdiagm cfdiag"
  for cfsubstream in ${cfsubstreams};do
    if [ -r ${expid}_${startyear}01.${day}_${cfsubstream}.codes ]; then
      save_file ${atmmod} log \
         ${expid}_${startyear}01.${day}_${cfsubstream}.codes \
         ${expid}_${atmmod}_${cfsubstream}.codes &
    fi
  done 
fi # code files

#-- NetCDFC streams: energy transport diagnostic and COSP files
date=${startdate}
while [[ $(later_date -- ${date} ${enddate}) = ${enddate} ]]; do
  year=$(format_date  -f4 -- ${date} | cut -f1 -d" ")
  month=$(format_date -f4 -- ${date} | cut -f2 -d" ")
  day=$(format_date   -f4 -- ${date} | cut -f3 -d" ")
  ym=${year}${month}
  if [[ -r ${expid}_${ym}.${day}_trdiag.nc ]]; then
    save_file ${atmmod} output ${expid}_${ym}.${day}_trdiag.nc \
                            ${expid}_${atmmod}_trdiag_${ym}.nc &
  else
    SAVE_status=${SAVE_status}/echam:trdiag${month}
  fi
  if [[ ${locosp:-false} = true ]]; then     # Warning: no saving if locosp=T !
    if [[ -r ${expid}_${ym}.${day}_cosp.nc ]]; then
      save_file ${atmmod} output ${expid}_${ym}.${day}_cosp.nc \
                              ${expid}_${atmmod}_cosp_${ym}.nc &
    else
      SAVE_status=${SAVE_status}/echam:cosp${month}
    fi
  fi
  date=$(calc_date plus -c${caltype} -M1 -- ${date})
done # months

#-- std output

if [[ "$lcouple" = true ]]; then
 if [[ -r atmout ]]; then
  save_file ${atmmod} log atmout \
            ${expid}_${atmmod}_atmout_${startdate}_${enddate} &
 else
  SAVE_status=${SAVE_status}/echam:atmout
 fi
fi

#-- COSP restart files
if [[ ${locosp:-false} = T ]]; then
  if [[ -r rerun_${expid}_tdiagm ]]; then
    save_file ${atmmod} restart rerun_${expid}_tdiagm \
                                rerun_${expid}_tdiagm_${enddate} &
  else
     SAVE_status=${SAVE_status}/echam:rerun:tdiagm
  fi
fi


#-- hydrology restart files

if [ $hd = true ]; then
  if [[ -r hdrestart.nc ]]; then
    save_file ${atmmod} restart hdrestart.nc rerun_${expid}_hd_${enddate}.nc &\
  else
    SAVE_status=${SAVE_status}/echam:hdrestart
  fi
fi


################################################################################
#
#  Save output of JSBACH
#
################################################################################

wait
printf "\n%s\n\t\t%s\n\t\t%s\n\n" "+++++ Save JSBACH output and restart files" \
       " from   ${work}/'expid'/work" " to     $data/'expid'"

suff=.grb
[[ "${atm_out_ztype}" = "1" ]] && suff=.sz

cd ${work}/${expid}/work; wait

SAVE_status=${SAVE_status:="0"}

substreams="jsbach land veg surf"

if [ ${jobnum} = 1 ]; then
 for substream in ${substreams};do
  if [ -r ${expid}_${startyear}01.01_${substream}.codes ]; then 
    save_file ${srfmod} log ${expid}_${startyear}01.01_${substream}.codes   \
                            ${expid}_${srfmod}_${substream}.codes &
  else
    SAVE_status=${SAVE_status}/jsbach:codes:${substream}
  fi
 done
fi

#-- save JSBACH raw output and restart files

substreams="jsbach land veg surf"
 
for substream in ${substreams};do
  [[ "${substream}" = "jsbach" ]] && datastream=${expid}_${srfmod} || \
    datastream=${expid}_${srfmod}_${substream}
  date=${startdate}
  while [[ $(later_date -- ${date} ${enddate}) = ${enddate} ]]; do
    year=$(format_date -f4  -- ${date} | cut -f1 -d" ")
    month=$(format_date -f4 -- ${date} | cut -f2 -d" ")
    day=$(format_date -f4   -- ${date} | cut -f3 -d" ")
    ym=${year}${month}
    if [ -r ${expid}_${ym}.${day}_${substream} ]; then
      save_file ${srfmod} output ${expid}_${ym}.${day}_${substream} \
                                 ${datastream}_${ym}${suff} &
    else
      SAVE_status=${SAVE_status}/jsbach:${substream}${month}
    fi
    date=$(calc_date plus -c${caltype} -M1 -- ${date})
  done # months
  [[ "$substream" = "land" ]] || {
    if [ -r rerun_${expid}_${substream} ]; then
      save_file ${srfmod} restart  rerun_${expid}_${substream} \
                                   rerun_${expid}_${substream}_${enddate} &
    else
      SAVE_status=${SAVE_status}/jsbach:rerun:${substream}
    fi;}
done          # datastreams

#------------------------------------------------------------------------------
#
# Check whether model integration finished successfully
#
#------------------------------------------------------------------------------
wait

year=$(format_date  -f4 -- ${date} | cut -f1 -d" ")
[[ "${groupwrite:-no}" = "no" ]] || { 
  chmod g+wx ${jobdir}/*.arch*${year}* ${jobdir}/*.post*${year}* \
             ${jobdir}/*.mon*${year}* || true ; }   #  */

if [[ ${RUN_status:-0} = 0 ]]; then
  printf "\n    |+ The model integration run finished successfully\n"
  if [[ ${SAVE_status:-0} = 0 ]]; then
    printf "\n    |+ All existing output files have been saved.\n"
  else
    printf "\n%s\n\n" \
         "      |- ERROR in file saving: SAVE_status = ${SAVE_status}"
    exit 1
  fi
else
  printf "\n%s\n\n" \
         "      |- ERROR occured: RUN_status = ${RUN_status}"
  if [[ ${SAVE_status:-0} = 0 ]]; then
    printf "\n    |+ All existing output files have been saved.\n"
  else
    printf "\n%s\n\n" \
         "      |- ERROR in file saving: SAVE_status = ${SAVE_status}"
  fi
  exit 1
fi

#------------------------------------------------------------------------------
#
#     8. SUBMISSION OF THE NEXT JOB
#
#------------------------------------------------------------------------------
cd  ${jobdir}

#
# Number of the next job
#

(( nextjob = ${jobnum} + 1 ))

#
# edit .date and .log file
#

space_error="no"

echo "${nextdate} ${nextjob}" > ${expid}.date.new || { 
  space_error="yes"; echo "Could not create ${expid}.date"; 
}
cp ${expid}.log ${expid}.log.new || { 
  space_error="yes"; echo "Could not save ${expid}.log"; 
}
echo "$(date +"${datefmt}") :  ${jobnum} ${nextdate} ${jobid}  - done" >> ${expid}.log.new || {
  space_error="yes"; echo "Could not append to ${expid}.log"; 
}

if [ "${space_error}" = "no" ]; then
  mv ${expid}.date.new ${expid}.date
  mv ${expid}.log.new ${expid}.log
  [[ "${groupwrite:-no}" = "no" ]] || { chmod g+wx ${expid}.date ${expid}.log || \
     printf "%s\n" "Problems occured with chmod on date/log files."; }
else
  echo "No disk space left or quota exceeded?"
  echo " - Show quota"
  quota
  exit
fi

#
# Check whether final date is reached
#

if [[ `later_date -- ${nextdate} ${findate}` = ${nextdate} ]]; then
  printf "\n%s\n" "    |+ Experiment over"
  echo "$(date +"${datefmt}") :  Experiment over" >> ${expid}.log
  chmod g-w ${outdir}/*/*.grb ${outdir}/*/*.nc || true
else
  qsub ${job}
fi

###############################################################################
#
#-- update run dates and submit expid.post script
#
cd ${jobdir}

#cp ${expid}.post  ${expid}.post.${nextdate}

#ed -s ${expid}.post.${nextdate} <<EOF
#1,100s/Jobnum/${jobnum}/
#1,100s/Startdate/${startdate}/
#1,100s/Nextdate/${nextdate}/
#1,100s/Inidate/${inidate}/
#1,100s/Findate/${findate}/
#w
#q
#EOF

if ( [ "post" = "post" ] || [ "post" = "arch" ] ) && [ -e ${home}/${expid}/scripts/.lock_postprocessing ]; then
   print "   |- "
   print "   |- ERROR : next job ${expid}.post.${nextdate} is not submitted, because"
   print "   |- ERROR : previous postprocessing job is terminated by an error."
   print "   |- ERROR : see lock file:  ${home}/${expid}/scripts/.lock_postprocessing"
   print "   |- "
else
   #submit -q ${queueing_system_pp:-LL} ${expid}.post.${nextdate}
  #qsub ${expid}.post.${nextdate}
  echo 'no post'
fi
#------------------------------------------------------------------------------
#   EPILOGUE
#------------------------------------------------------------------------------

wait; ${job_account}

printf "\n%s\t%s\n"  " End of script at " "$(date +'%b %d %T') on $(hostname)"

exit


